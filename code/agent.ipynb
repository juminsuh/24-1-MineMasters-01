{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5QKSDv7xFXAxipgG/TYJO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2xPy2znzyvU3"},"outputs":[],"source":["BATCH_SIZE = 64\n","MEMORY_SIZE = 50000\n","MEMORY_SIZE_MIN = 1000\n","\n","EPSILON = 0.99\n","EPSILON_DECAY = 0.999975\n","EPSILON_MIN = 0.01\n","DISCOUNT_FACTOR = 0.1\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","LEARNING_RATE = 0.001\n","LEARNING_RATE_DECAY = 0.99975\n","LEARN_EPOCH = 1000\n","\n","UPDATE_TIME = 5"]},{"cell_type":"code","source":["class Agent:\n","\n","    def __init__(self, state_size, action_size):\n","\n","        self.state_size = state_size\n","        self.action_size = action_size\n","\n","        # memory\n","        self.batch_size = BATCH_SIZE\n","        self.memory_size = MEMORY_SIZE\n","        self.memory_size_min = MEMORY_SIZE_MIN\n","        self.memory = deque(maxlen = self.memory_size)\n","\n","        # epsilon\n","        self.epsilon = EPSILON\n","        self.epsilon_decay = EPSILON_DECAY\n","        self.epsilon_min = EPSILON_MIN\n","        self.discount_factor = DISCOUNT_FACTOR\n","\n","        self.device = DEVICE\n","\n","        # 인공신경망 model, 타깃신경망 target_model\n","        self.learning_rate = LEARNING_RATE\n","        self.learning_rate_decay = LEARNING_RATE_DECAY\n","        self.learn_epoch = LEARN_EPOCH\n","        self.loss = nn.MSELoss()\n","        self.loss_list = []\n","        self.model = NeuralNet(self.action_size).to(self.device)\n","        self.target_model = NeuralNet(self.action_size).to(self.device)\n","        self.optimizer = optim.Adam(self.model.parameters(), lr = self.learning_rate, eps = 1e-4)\n","        self.lr_scheduler = lr_scheduler.CyclicLR(self.optimizer, base_lr=0.00005,\n","                                              step_size_up=5, max_lr=0.01,\n","                                              gamma=0.5, mode='exp_range')\n","\n","        # 일정 time step(한 episode)이 지나면 target 신경망을 인공신경망으로 대체\n","        self.update_time = UPDATE_TIME\n","        self.update_target_model()\n","\n","    # 인공신경망의 파라미터 -> target model의 파라미터\n","    def update_target_model(self):\n","        self.target_model.load_state_dict(self.model.state_dict())\n","\n","    # 엡실론 - 탐욕 정책\n","    def get_action(self, state):\n","\n","        random_prob = np.random.rand()\n","        if random_prob <= self.epsilon:\n","          action_idx = np.random.choice(range(self.action_size))\n","\n","        else:\n","          self.model.eval()\n","\n","          with torch.no_grad():\n","            state = torch.tensor(state, dtype = torch.float32).to(self.device)\n","            q_value = self.model(state.unsqueeze(0).unsqueeze(0))\n","\n","            _, action_idx = torch.max(q_value, dim = 1)\n","            action_idx = action_idx.item()\n","\n","        return action_idx\n","\n","    def append_sample(self, state, action, next_state, reward, exploded, done):\n","        # done: 게임이 끝났으면 True\n","        # 이때 reward를 다르게 줌\n","        self.memory.append((state, action, next_state, reward, exploded, done))\n","\n","    def train_model(self):\n","\n","        # 엡실론 업데이트\n","        if self.epsilon > self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","\n","        mini_batch = random.sample(self.memory, self.batch_size)\n","        states, actions, next_states, rewards, explodeds, dones = zip(*mini_batch)\n","\n","        states = torch.tensor(states, dtype = torch.float32).unsqueeze(1).to(self.device)\n","        actions = torch.tensor(actions, dtype = torch.int64).to(self.device)\n","        next_states = torch.tensor(next_states, dtype = torch.float32).unsqueeze(1).to(self.device)\n","        rewards = torch.tensor(rewards, dtype = torch.float32).to(self.device).reshape(-1, 1)\n","        explodeds = torch.tensor(explodeds, dtype = torch.int64).to(self.device).reshape(-1, 1)\n","        dones = torch.tensor(dones, dtype = torch.int64).to(self.device).reshape(-1, 1)\n","\n","\n","        self.model.train()\n","        self.target_model.eval()\n","\n","        # 현재 상태에 대한 action별 큐함수(인공신경망의 예측)\n","        predicts = self.model(states)\n","\n","        with torch.no_grad():\n","\n","            target_predict, _ = torch.max(self.target_model(next_states), dim = 1)\n","            target_pred = target_predict.reshape(-1, 1)\n","\n","        # 벨만 최적 방정식\n","        targets = rewards + (1 - dones) * self.discount_factor * target_pred\n","        targets = targets.flatten()\n","\n","        target_q_values = copy.deepcopy(predicts.detach())\n","        target_q_values[range(BATCH_SIZE), actions] = targets\n","\n","        loss = self.loss(predicts, target_q_values)\n","        self.loss_list.append(loss.item())\n","\n","        # 가중치 업데이트\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()"],"metadata":{"id":"w-5dnTOny0Fj"},"execution_count":null,"outputs":[]}]}
